1.hadoop与spark并行计算的区别？
hadoop的job只有map和reduce操作，表达能力比较欠缺，而且在mr的过程中会重复读取hdfs，造成大量的IO操作，多个job需要自己管理关系。
spark的迭代计算都是基于内存的，提供了大量的rdd操作，通过DAG图可以实现很好的容错。

2.什么是窄依赖和宽依赖？map操作是窄依赖还是宽依赖？列举一个宽依赖的操作（开放性问题）。
窄依赖的子rdd对应常数个父rdd分区，宽依赖的子rdd对应所有的父rdd分区。map操作是窄依赖。groupbykey是宽依赖。

3.structured streaming流式写出支持几种类型?如何实现ForeachWriter？（实现哪几个函数）
五种：本地或者HDFS file、console、memory、kafka、Foreach。
实现ForeachWriter必须实现open，process，close三个函数，其中open函数里实现目标端的连接，process函数里实现数据处理业务，close函数实现连接关闭。

4.structured streaming如何保证端到端的一次执行？如何解决多流聚合的问题？
通过检查点（checkpoint）和预写日志的方式确保端到端的一次执行。
如何解决多流聚合：
第一种：中间结果写入kafka，再读取kafka数据形成单流。
第二种：利用foreachBatch形成批处理。

5.什么是数据倾斜？如何解决？
数据分配严重不均匀会形成数据倾斜，导致某些节点或者分区处理的数据显著的高于其他的节点或者分区，从而形成大job，进而形成这个阶段执行最慢的部分，是整个作业执行的瓶颈。
如何解决：
第一种：保证数据源均衡分布（例如hbase加盐等）
第二种：大数据集做过滤再repartion。
第三种：小表进行广播，实现map端join，从而减少shuffle。

6.spark程序优化策略？（开放性问题）
多次使用的数据cache起来，多采用预聚合，调大paralism并行度等。

7.kafka数据丢失问题如何解决？
第一步：定位是消费端数据丢失还是kafka接收数据之间就已经丢失。
数据重放（换个消费group），重新消费。如果消费端丢失，不可能一样。
第二步：如何解决？（开放性环节）
如果是接收之前丢失跟kafka没关系，需重新定位。如果是kafka消费端丢失，需要重新修改配置kafka消息重试机制（默认是1秒重试），在网络负载很高过着磁盘很忙的情况下，网络中断时间很可能超过1秒。